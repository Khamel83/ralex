---
# Anti-Marketing Philosophy
# Factual, measurable descriptions only - no hype or subjective claims

anti_marketing_manifesto:
  principle: "Facts and metrics only - let the work speak for itself"
  
  what_we_avoid:
    marketing_language:
      - "Amazing, incredible, revolutionary, game-changing"
      - "Best-in-class, industry-leading, cutting-edge"
      - "Seamless, effortless, intuitive, powerful"
      - "Next-generation, state-of-the-art, innovative"
      
    subjective_claims:
      - "Easy to use" → Instead: "Setup in 3 commands"
      - "Fast performance" → Instead: "Processes 100 requests/minute"
      - "Great user experience" → Instead: "95% user task completion rate"
      - "Reliable system" → Instead: "99.9% uptime over 30 days"
      
    unmeasurable_benefits:
      - "Dramatically improves productivity"
      - "Significantly reduces costs"
      - "Greatly enhances workflow"
      - "Substantially better than alternatives"

what_we_use_instead:
  exact_measurements:
    - "Reduces API costs by 23% vs baseline"
    - "Routes queries in <3 seconds average"
    - "Requires 2 minutes setup time"
    - "Uses 40% fewer tokens per request"
    
  technical_specifications:
    - "OpenAI-compatible API endpoints"
    - "Supports 15 model providers via OpenRouter"
    - "YAML-based configuration system"
    - "REST API with JSON responses"
    
  quantified_comparisons:
    - "50% lower token usage vs direct API calls"
    - "3x faster than manual model selection"
    - "$0.002 per request vs $0.005 baseline"
    - "Requires 3 config changes vs 15 code changes"
    
  factual_descriptions:
    - "Terminal-native AI coding assistant"
    - "Semantic routing with cost optimization"
    - "iOS mobile interface via OpenCat app"
    - "Continuous deployment workflow"

implementation_rules:
  documentation:
    - State what the system does, not how great it is
    - Include actual numbers with measurement methods
    - Show comparisons with baseline metrics
    - List specific technical capabilities
    
  feature_descriptions:
    - "Intelligence router classifies queries in 2 seconds"
    - NOT: "Advanced AI-powered query classification"
    - "Logs cost data to .ralex/cost_log.txt"
    - NOT: "Comprehensive cost analytics dashboard"
    
  user_communication:
    - Tell users exactly what will happen
    - Give specific time estimates
    - Provide measurable outcomes
    - Include failure scenarios and limitations
    
  success_stories:
    - "Reduced monthly API costs from $45 to $31"
    - NOT: "Massive cost savings for our users"
    - "Setup completed in 4 minutes vs estimated 5"
    - NOT: "Incredibly fast deployment experience"

metrics_location_standards:
  where_to_put_numbers:
    config_files:
      - ".env for cost thresholds and limits"
      - "intelligence-config.yaml for performance targets"
      - "cost_log.txt for actual usage metrics"
      
    documentation:
      - "README.md for headline numbers only"
      - "METRICS.md for detailed performance data"
      - "Inline comments for specific function performance"
      
    code:
      - "Constants for measurable thresholds"
      - "Logging for runtime metrics"
      - "Comments for performance expectations"

examples_correct_vs_incorrect:
  project_descriptions:
    correct: "Terminal AI assistant with semantic routing, reduces API costs 20%+"
    incorrect: "Revolutionary AI coding companion that transforms your development workflow"
    
  feature_announcements:
    correct: "Added intelligence routing - classifies queries in <3sec, reduces costs 23%"
    incorrect: "Introducing our groundbreaking intelligence optimization system"
    
  user_onboarding:
    correct: "Run @execute-task command, wait 120-150 minutes for completion"
    incorrect: "Experience seamless setup with our intuitive automation system"
    
  problem_statements:
    correct: "OpenAI API costs $0.03/1K tokens, need cheaper routing for simple queries"
    incorrect: "API costs are too expensive and need better optimization"

validation_checklist:
  before_publishing_any_content:
    - "Does this include specific measurements?"
    - "Could a user verify these claims?"
    - "Are comparisons based on actual data?"
    - "Would this work as a technical specification?"
    - "Does this help users make informed decisions?"
    
  red_flags_to_remove:
    - "Any adjective that could apply to a competitor"
    - "Any claim without a specific number"
    - "Any benefit without a measurement method"
    - "Any description that sounds like advertising"